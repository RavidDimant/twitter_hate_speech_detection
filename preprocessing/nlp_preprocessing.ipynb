{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "learn-env",
   "display_name": "learn-env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NLP Preprocessing Notebook\n",
    "\n",
    "The purpose of this notebook is to conduct the preprocessing steps that are necessary for text data in NLP. This includes tokenizing, removing stop words, vectorizing, etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from sklearn.feature_extraction import text \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix, roc_curve, auc, classification_report\n",
    "import pickle"
   ]
  },
  {
   "source": [
    "### Loading in the clean dataframe from `data_cleaning.ipynb`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our corpus\n",
    "clean_df = pd.read_pickle('../pickle/clean_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   total_votes  hate_speech_votes  other_votes  label  \\\n",
       "0            3                  0            3      0   \n",
       "1            3                  0            3      0   \n",
       "2            3                  0            3      0   \n",
       "3            3                  0            3      0   \n",
       "4            6                  0            6      0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                       round_1_tweet  \n",
       "0     as a woman you shouldnt complain about clea...  \n",
       "1     boy dats coldtyga dwn bad for cuffin dat ho...  \n",
       "2     dawg   you ever fuck a bitch and she sta to...  \n",
       "3                             she look like a tranny  \n",
       "4     the shit you hear about me might be true or...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_votes</th>\n      <th>hate_speech_votes</th>\n      <th>other_votes</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>round_1_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n      <td>as a woman you shouldnt complain about clea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n      <td>boy dats coldtyga dwn bad for cuffin dat ho...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n      <td>dawg   you ever fuck a bitch and she sta to...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n      <td>she look like a tranny</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n      <td>the shit you hear about me might be true or...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "source": [
    "### Creating `tweet_df` with only cleaned tweets column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_df = pd.DataFrame(tweet_data)\n",
    "\n",
    "tweet_df = clean_df[['round_1_tweet', 'label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       round_1_tweet  label\n",
       "0     as a woman you shouldnt complain about clea...      0\n",
       "1     boy dats coldtyga dwn bad for cuffin dat ho...      0\n",
       "2     dawg   you ever fuck a bitch and she sta to...      0\n",
       "3                             she look like a tranny      0\n",
       "4     the shit you hear about me might be true or...      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round_1_tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>as a woman you shouldnt complain about clea...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>boy dats coldtyga dwn bad for cuffin dat ho...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dawg   you ever fuck a bitch and she sta to...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>she look like a tranny</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the shit you hear about me might be true or...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tweet_df['round_1_tweet']\n",
    "target = tweet_df['label']"
   ]
  },
  {
   "source": [
    "## Remove Stop Words & Tokenize\n",
    "We can use NLTK's built-in library of stop words."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "    return stopwords_removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the above function to our data/features \n",
    "processed_data = list(map(process_tweet, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20277"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "total_vocab = set()\n",
    "for comment in processed_data:\n",
    "    total_vocab.update(comment)\n",
    "len(total_vocab)"
   ]
  },
  {
   "source": [
    "## Lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with all lemmatized outputs\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "lemmatized_output = []\n",
    "\n",
    "for listy in processed_data:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in listy])\n",
    "    lemmatized_output.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = lemmatized_output\n",
    "y_lem = target"
   ]
  },
  {
   "source": [
    "# pickle these for modeling\n",
    "pickle_out = open('../pickle/X_lem.pkl','wb')\n",
    "pickle.dump(X_lem, pickle_out)\n",
    "pickle_out.close()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lem.to_pickle('../pickle/y_lem.pkl')"
   ]
  },
  {
   "source": [
    "### Now `X_lem` and `y_lem` are ready to be brought over to the modeling notebooks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}